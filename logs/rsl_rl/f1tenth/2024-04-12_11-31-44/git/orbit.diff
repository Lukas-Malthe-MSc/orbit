--- git status ---
HEAD detached from 4742908
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
  (commit or discard the untracked or modified content in submodules)
	modified:   rsl_rl (untracked content)
	modified:   source/extensions/omni.isaac.orbit/omni/isaac/orbit/envs/mdp/actions/ackermann_actions.py
	modified:   source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/f1tenth_env_cfg.py
	modified:   source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/randomizations.py
	modified:   source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/rewards.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/rsl_rl b/rsl_rl
--- a/rsl_rl
+++ b/rsl_rl
@@ -1 +1 @@
-Subproject commit 0f5dc984599ef88f6028e80282a88f1001912de0
+Subproject commit 0f5dc984599ef88f6028e80282a88f1001912de0-dirty
diff --git a/source/extensions/omni.isaac.orbit/omni/isaac/orbit/envs/mdp/actions/ackermann_actions.py b/source/extensions/omni.isaac.orbit/omni/isaac/orbit/envs/mdp/actions/ackermann_actions.py
index e8a7afd..76b5902 100644
--- a/source/extensions/omni.isaac.orbit/omni/isaac/orbit/envs/mdp/actions/ackermann_actions.py
+++ b/source/extensions/omni.isaac.orbit/omni/isaac/orbit/envs/mdp/actions/ackermann_actions.py
@@ -100,22 +100,13 @@ class AckermannAction(ActionTerm):
     Operations.
     """
 
-
-
     def process_actions(self, actions):
         # store the raw actions
-        self._raw_actions[:] = torch.tanh(actions)
-        
-        print(f"Raw actions: {self._raw_actions}")
+        self._raw_actions[:] = torch.tanh(actions) # Normalize the actions to [-1, 1]
         
-        self._processed_actions = self.raw_actions * self._scale + self._offset
-        self._processed_actions[:, 0] = torch.clamp(self._processed_actions[:, 0], min=-self.max_speed, max=self.max_speed)
-        self._processed_actions[:, 1] = torch.clamp(self._processed_actions[:, 1], min=-self.max_steering_angle, max=self.max_steering_angle)
-        print(f"Processed actions: {self._processed_actions}")
-
+        self._processed_actions = self.raw_actions * self._scale + self._offset # Scale and offset the actions
             
     def apply_actions(self):
-        
 
         left_rotator_angle, right_rotator_angle, wheel_speeds = self. calculate_ackermann_angles_and_velocities(
             target_velocity=self.processed_actions[:, 0],  # Velocity for all cars
@@ -123,9 +114,6 @@ class AckermannAction(ActionTerm):
         )
         wheel_angles = torch.stack([left_rotator_angle, right_rotator_angle], dim=1)
 
-        # wheel_angles = torch.zeros(wheel_speeds.shape[0], 2, device=self.device)
-        # wheel_speeds = torch.ones(wheel_speeds.shape[0], 4, device=self.device)
-
         self._asset.set_joint_velocity_target(wheel_speeds, joint_ids=self._wheel_ids)
         self._asset.set_joint_position_target(wheel_angles, joint_ids=self._steering_ids)
 
@@ -140,7 +128,6 @@ class AckermannAction(ActionTerm):
         target_steering_angle_rad = target_steering_angle_rad.float()
         target_velocity = target_velocity.float()
         
-        
         # Calculating the turn radius from the steering angle
         tan_steering = torch.tan(target_steering_angle_rad)
         R = torch.where(tan_steering == 0, torch.full_like(tan_steering, 1e6), L / tan_steering)
@@ -164,46 +151,7 @@ class AckermannAction(ActionTerm):
         wheel_speeds = torch.stack([v_back_left, v_back_right, v_front_left, v_front_right], dim=1) / wheel_radius
         
         return delta_left, delta_right, wheel_speeds
-    
-#     def calculate_ackermann_angles_and_velocities(self, target_steering_angle_rad, target_velocity):
-        
-        
-# #           B
-# #           |\
-# #           | \
-# #           |  \
-# #          a|   \c
-# #           |    \
-# #           |     \
-# #           |______\
-# #           C   b   A
-# #
-# #           Tan(B)=b/a   <--->  b=a*Tan(B)
-# # In our case we know C=90, a = base_length and B = 90-steering_angle
-
-#         R_nutnut = self.base_length * torch.tan(abs((0.5*torch.pi)-target_steering_angle_rad))
-
-    
-#         inner_diff = torch.atan(self.base_length / (R - self.base_width / 2))
-#         outer_diff = torch.atan(self.base_length / (R + self.base_width / 2))
-        
-        
-        
-        
-        
-        
-        
-        
-#         # If target steering is positive, we turn right
-#         if target_steering_angle_rad > 0:
-#             left_rotator_angle = outer_diff
-#             right_rotator_angle = inner_diff
-            
-#             left_front_radius = 0
-#             right_front_radius = 0
-#             left_back_radius = 0
-#             right_back_radius = 0
-            
+
             
 
         
diff --git a/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/f1tenth_env_cfg.py b/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/f1tenth_env_cfg.py
index ebdd937..328df3d 100644
--- a/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/f1tenth_env_cfg.py
+++ b/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/f1tenth_env_cfg.py
@@ -9,7 +9,7 @@ from omni.isaac.orbit.sensors.lidar.lidar_cfg import LidarCfg
 from rich import print
 
 import omni.isaac.orbit.sim as sim_utils
-from omni.isaac.orbit.assets import ArticulationCfg, AssetBaseCfg
+from omni.isaac.orbit.assets import ArticulationCfg, AssetBaseCfg, RigidObjectCfg
 from omni.isaac.orbit.envs import RLTaskEnvCfg
 from omni.isaac.orbit.managers import ObservationGroupCfg as ObsGroup
 from omni.isaac.orbit.managers import ObservationTermCfg as ObsTerm
@@ -29,7 +29,7 @@ import omni.isaac.orbit_tasks.f1tenth.mdp as mdp
 ##
 from omni.isaac.orbit_assets.f1tenth import F1TENTH_CFG  # isort:skip
 
-
+import random
 ##
 # Scene definition
 ##
@@ -43,13 +43,22 @@ Train commmand:
 $ ./orbit.sh -p source/standalone/workflows/rsl_rl/train.py --task F1tenth-v0 --headless --offscreen_render --num_envs 4096
 
 Play command:
-<<<<<<< HEAD
-$ ./orbit.sh -p source/standalone/workflows/rsl_rl/play.py --task F1tenth-v0 --num_envs 1 --load_run 2024-04-11_15-43-09 --checkpoint model_49.pt
-=======
-$ ./orbit.sh -p source/standalone/workflows/rsl_rl/play.py --task F1tenth-v0 --num_envs 4 --load_run 2024-04-11_13-40-21 --checkpoint model_40.pt
->>>>>>> 10847cde537700ecc806bf6eeb9c68f380e2004c
+$ ./orbit.sh -p source/standalone/workflows/rsl_rl/play.py --task F1tenth-v0 --num_envs 1 --load_run 2024-04-12_11-19-51 --checkpoint model_100.pt
 
 """
+
+
+
+
+def random_spawn_position():
+    # Define boundaries for random spawn locations
+    x_min, x_max = -5.0, 5.0  # Adjust these values to your requirements
+    y_min, y_max = -5.0, 5.0  # Adjust these values to your requirements
+    z_pos = 2.0  # Assuming you want to keep the Z position fixed
+    x = random.uniform(x_min, x_max)
+    y = random.uniform(y_min, y_max)
+    return (x, y, z_pos)
+
 @configclass
 class F1tenthSceneCfg(InteractiveSceneCfg):
     """Configuration for a cart-pole scene."""
@@ -78,12 +87,23 @@ class F1tenthSceneCfg(InteractiveSceneCfg):
     #     init_state=AssetBaseCfg.InitialStateCfg(pos=(5.0, 4.0, 0.0),rot=(0.0, 0.0, 0.0, 0.0)),
     # )
 
-    # obstacle = [AssetBaseCfg(
-    #     prim_path="{ENV_REGEX_NS}/target",
-    #     spawn=sim_utils.CuboidCfg(size=(0.1, 2.0, 0.1)),
-    #     init_state=AssetBaseCfg.InitialStateCfg(pos=(0.0, 0.0, 0.0),
-    #                                             rot=(0.0, 0.0, 0.0, 0.0)),
-    # )for i in range(4)]
+    obstacle1 = RigidObjectCfg(
+        prim_path="{ENV_REGEX_NS}/obstacle1",
+        spawn=sim_utils.ConeCfg(radius=0.15, height=0.5, 
+                                rigid_props=sim_utils.RigidBodyPropertiesCfg(rigid_body_enabled=True),
+                                collision_props=sim_utils.CollisionPropertiesCfg()),
+        init_state=RigidObjectCfg.InitialStateCfg(pos=random_spawn_position(),
+                                                rot=(1.0, 0.0, 0.0, 0.0)),
+    )
+
+    # obstacle2 = RigidObjectCfg(
+    #     prim_path="{ENV_REGEX_NS}/obstacle2",
+    #     spawn=sim_utils.ConeCfg(radius=0.15, height=0.5, 
+    #                             rigid_props=sim_utils.RigidBodyPropertiesCfg(rigid_body_enabled=True),
+    #                             collision_props=sim_utils.CollisionPropertiesCfg()),
+    #     init_state=RigidObjectCfg.InitialStateCfg(pos=random_spawn_position(),
+    #                                             rot=(1.0, 0.0, 0.0, 0.0)),
+    # )
     
     
     # f1tenth
@@ -121,13 +141,6 @@ class F1tenthSceneCfg(InteractiveSceneCfg):
         )
     )
 
-    
-    # TODO: Add touch sensor that can register collisions with the walls
-    # Check ant_env_cfg.py for an example of how to add a touch sensor
-
-
-
-
 ##
 # MDP settings
 ##
@@ -148,7 +161,7 @@ class ActionsCfg:
     ackermann_action = mdp.AckermannActionCfg(asset_name="robot", 
                                   wheel_joint_names=["wheel_back_left", "wheel_back_right", "wheel_front_left", "wheel_front_right"], 
                                   steering_joint_names=["rotator_left", "rotator_right"], 
-                                  base_width=0.25, base_length=0.35, wheel_radius=0.05, scale=(2.0, torch.pi/4), offset=(0.0, 0.0)) #TODO: adjust max speed
+                                  base_width=0.25, base_length=0.35, wheel_radius=0.05, scale=(3.0, torch.pi/4), offset=(0.0, 0.0)) #TODO: adjust max speed
 
 @configclass
 class ObservationsCfg:
@@ -185,8 +198,7 @@ class RandomizationCfg:
         params={
             "asset_cfg": SceneEntityCfg("robot"), 
             "pose_range": {
-                # "x": (-0.3, 0.3),  # X position range from -5 to 5
-                "x": (0.0, 0.0),  # X position range from -5 to 5
+                "x": (1.0, 1.0),  # X position range from -5 to 5
                 "y": (0.0, 0.0),  # Y position range from -5 to 5
                 "z": (0.0, 0.2),   # Z position range from 0 to 2 (assuming starting on the ground)
                 "roll": (0.0, 0.0),  # Roll orientation range from -pi to pi
@@ -204,6 +216,11 @@ class RandomizationCfg:
         },
     )
     
+    # randomize_obstacle1 = RandTerm(
+    #     func=mdp.randomize_obstacle_position,
+    #     mode="reset",
+    #     params={"obstacle_cfg": SceneEntityCfg("obstacle1")}
+    # )
     
 
 
@@ -217,32 +234,22 @@ class RewardsCfg:
     # terminating = RewTerm(func=mdp.is_terminated, weight=-10.0)
     
     # -- Task: Drive forward
-    # forward_velocity_reward = RewTerm(func=mdp.forward_velocity, weight=1.0)
+    forward_velocity_reward = RewTerm(func=mdp.forward_velocity, weight=1.0)
     # distance_traveled_reward = RewTerm(func=mdp.distance_traveled_reward, weight=1.0, params={"asset_cfg": SceneEntityCfg("robot")})
-    speed_scaled_distance_reward = RewTerm(func=mdp.speed_scaled_distance_reward, weight=1.0, params={"asset_cfg": SceneEntityCfg("robot")})
-    
-    # within_starting_location = RewTerm(func=mdp.within_starting_location, weight=1.0, params={"asset_cfg": SceneEntityCfg("robot"), "threshold": 1.5})
-    
-    # update_pass_counters = RewTerm(func=mdp.update_pass_counters, weight=1.0, params={"asset_cfg": SceneEntityCfg("robot"), "threshold": 0.5})
-    
-    # -- Task: Move to center of track
-    # lidar_deviation = RewTerm(func=mdp.lidar_mean_absolute_deviation, weight=-1.0, params={"sensor_cfg": SceneEntityCfg("lidar")})
-    
-    # -- Task: Move to position
-    # move_to_position = RewTerm(func=mdp.move_to_position, weight=-1.0, params={"target": (5.0, 4.0), "asset_cfg": SceneEntityCfg("robot")})
+    # speed_scaled_distance_reward = RewTerm(func=mdp.speed_scaled_distance_reward, weight=1.0, params={"asset_cfg": SceneEntityCfg("robot")})
     
     # -- Penalty
-    # steering_angle_position = RewTerm(
-    #     func=mdp.joint_pos_target_l2,
-    #     weight=-0.05,
-    #     params={"asset_cfg": SceneEntityCfg("robot", joint_names=['rotator_left', 'rotator_right']), "target": 0.0}
-    # )
+    steering_angle_position = RewTerm(
+        func=mdp.joint_pos_target_l2,
+        weight=-0.05,
+        params={"asset_cfg": SceneEntityCfg("robot", joint_names=['rotator_left', 'rotator_right']), "target": 0.0}
+    )
     
-    # # -- Penalty
-    # min_lidar_distance = RewTerm(
-    #     func=mdp.lidar_min_distance,
-    #     weight=-0.01,
-    #     params={"sensor_cfg": SceneEntityCfg("lidar")})
+    # -- Penalty
+    min_lidar_distance = RewTerm(
+        func=mdp.lidar_min_distance,
+        weight=-0.01,
+        params={"sensor_cfg": SceneEntityCfg("lidar")})
     
 @configclass
 class TerminationsCfg:
diff --git a/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/randomizations.py b/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/randomizations.py
index c82db7f..41e3f2b 100644
--- a/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/randomizations.py
+++ b/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/randomizations.py
@@ -3,24 +3,18 @@ from __future__ import annotations
 import torch
 from typing import TYPE_CHECKING
 
-from omni.isaac.orbit.assets import AssetBaseCfg
+from omni.isaac.orbit.assets import AssetBaseCfg, RigidObjectCfg, Articulation, RigidObject, AssetBase
 import omni.isaac.orbit.sim as sim_utils
+from omni.isaac.orbit.managers import SceneEntityCfg
 
 if TYPE_CHECKING:
-    from omni.isaac.orbit.envs import RLTaskEnv
+    from omni.isaac.orbit.envs import RLTaskEnv, BaseEnv
     
 import random
 
-# def spawn_obstacles(env: RLTaskEnv, asset_cfg: AssetBaseCfg, num_obstacles: int, obstacle_type: str) -> None:
-#     """Spawn obstacles in the environment."""
-#     # spawn obstacles
-#     for _ in range(num_obstacles):
-#         # randomize the position of the obstacle
-#         # spawn the obstacle
-#         obstacle = AssetBaseCfg(
-#             prim_path="{ENV_REGEX_NS}/obstacle",
-#             spawn=sim_utils.CuboidCfg(size=(0.1, 2.0, 0.1)),
-#             init_state=AssetBaseCfg.InitialStateCfg(pos=(0.0, 0.0, 0.0),
-#                                                     rot=(0.0, 0.0, 0.0, 0.0)),
-#         )
+# randomize obstacle position
+def randomize_obstacle_position(env: RLTaskEnv, obstacle_cfg: SceneEntityCfg):
+    obstacle: RigidObjectCfg = env.scene[obstacle_cfg.name]
 
+    obstacle.InitialStateCfg().pos = (random.uniform(-5, 5), random.uniform(-5, 5), 0)
+    
\ No newline at end of file
diff --git a/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/rewards.py b/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/rewards.py
index 57ab953..8fc545d 100644
--- a/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/rewards.py
+++ b/source/extensions/omni.isaac.orbit_tasks/omni/isaac/orbit_tasks/f1tenth/mdp/rewards.py
@@ -95,12 +95,9 @@ def speed_scaled_distance_reward(env: RLTaskEnv, asset_cfg: SceneEntityCfg = Sce
     # Calculate the Euclidean distance traveled since the last step
     distance_traveled = torch.norm(position_difference, dim=1)
 
-    # Assuming env.step_dt represents the time elapsed between steps
-    time_elapsed = env.step_dt
-
     # Calculate the reward as distance divided by time (speed)
     # In environments with consistent time steps, you could simply use `distance_traveled` as the reward.
-    reward = distance_traveled / time_elapsed
+    reward = distance_traveled / env.step_dt
 
     # Update the previous position for the next timestep
     env.custom_data['prev_position'] = current_position.clone()